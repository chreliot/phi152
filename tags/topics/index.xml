<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>topics on PHI 152</title>
    <link>http://chreliot.github.io/phi152/tags/topics/</link>
    <description>Recent content in topics on PHI 152</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 May 2022 14:03:11 -0400</lastBuildDate><atom:link href="http://chreliot.github.io/phi152/tags/topics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Topic 8: Wrap Up</title>
      <link>http://chreliot.github.io/phi152/topics/wrap-up/</link>
      <pubDate>Tue, 10 May 2022 14:03:11 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/wrap-up/</guid>
      <description>Reading Aschwanden, Christie. 2019. “Just So Science.” Chapter 1 of Good to Go What the Athlete in All of Us Can Learn from the Strange Science of Recovery. W. W. Norton &amp;amp; Co. Available on Blackboard &amp;gt; Course Documents. </description>
    </item>
    
    <item>
      <title>Topic 4: Bayesianism</title>
      <link>http://chreliot.github.io/phi152/topics/bayesianism/</link>
      <pubDate>Tue, 29 Mar 2022 12:41:15 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/bayesianism/</guid>
      <description>Bayesianism, as an approach to inductive reasoning, focuses on updating our beliefs in light of new evidence. It is built around a simple formula that expresses a relationship between probabilities.
Reading Hacking, Chapter 7 “Bayes&amp;rsquo; Rule” (pages 69–77) Hacking, Chapter 15 “Learning from Experience” (pages 171–188) Hacking, Chapter 21 “Learning from Experience as an Evasion of the Problem of Induction” (4 pages) — and if you&amp;rsquo;re not feeling sufficiently familiar with “the problem of induction” (from our discussion of Hume), optionally look at the first pages of Chapter 20 Slides Introducing Bayesianism Learning questions What do each of the terms mean in the basic version of Bayes&amp;rsquo;s Rule?</description>
    </item>
    
    <item>
      <title>Topic 3: Probability</title>
      <link>http://chreliot.github.io/phi152/topics/probability/</link>
      <pubDate>Thu, 10 Feb 2022 10:18:13 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/probability/</guid>
      <description>Here we set up some basic ideas about probability which will are necessary for understanding the approaches to scientific justification scientists have used most during the last fifty years.
Reading Hacking, Introduction to Probability and Inductive Logic Chapter 3 “The Gambler&amp;rsquo;s Fallacy” This chapter introduces the basic concepts randomness, independence, and probability model but overall it&amp;rsquo;s pitched to give you a feel for some probability ideas. You might read it more quickly than Chapter 4↓.</description>
    </item>
    
    <item>
      <title>Topic 2: Early Methods</title>
      <link>http://chreliot.github.io/phi152/topics/early-methods/</link>
      <pubDate>Sun, 06 Feb 2022 14:22:38 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/early-methods/</guid>
      <description>As modern science emerged, its practitioners tried to describe how they were reasoning, and how others should reason, to do science. They came to quite different answers! This unit looks quickly at a few landmarks from the period 1600–1965.
Reading Francis Bacon, The New Organon (1620). Read Book 2, sections 10–16 (bottom right of page 53 to page 64 of the linked PDF). Focus on the figuring out the overall method, skimming the specific scientific information in the middle to get a general sense of what&amp;rsquo;s going on.</description>
    </item>
    
    <item>
      <title>Topic 1: Logic</title>
      <link>http://chreliot.github.io/phi152/topics/logic/</link>
      <pubDate>Sun, 30 Jan 2022 22:16:17 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/logic/</guid>
      <description>Does science have a logic? Could it be what we call “deductive logic,” (which is the focus of other courses like PHI 154 Symbolic Logic)? What is deductive logic? Is non-deductive logic possible? What could “inductive logic” be? Could it be the logic of science?
Reading (This is what you should read for this section. The due dates appear on the front page schedule.)
Salmon, Wesley C. “The Scope of Logic,” chapter 1 of Logic, 1984.</description>
    </item>
    
    <item>
      <title>Topic 7: Decision Theory</title>
      <link>http://chreliot.github.io/phi152/topics/decision-theory/</link>
      <pubDate>Wed, 05 May 2021 14:30:06 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/decision-theory/</guid>
      <description>Decision theory offers a framework for using knowledge to make decisions. To do this, it offers a way of integrating probabilities and values. And it offers some guidelines for choosing different probability/value combinations under different conditions.
Reading Hacking, “Expected Value,” chapter 8 of Introduction to Probability and Inductive Logic. Read pages 79–82 with care. Hacking, “Maximizing Expected Value,” chapter 9 of Introduction to Probability and Inductive Logic. Read pages 98–108. Hacking, “Decision under Uncertainty,” chapter 10 of Introduction to Probability and Inductive Logic Optional reading I&amp;rsquo;ve selected 15 total pages for you from Chapters 8–9, but there is a lot else that&amp;rsquo;s interesting in those chapters.</description>
    </item>
    
    <item>
      <title>Topic 5: Frequentism</title>
      <link>http://chreliot.github.io/phi152/topics/frequentism/</link>
      <pubDate>Tue, 23 Feb 2021 14:43:16 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/frequentism/</guid>
      <description>Next, we examine the second main, contemporary approach to scientific reasoning, based in the frequentist understanding of probability. At the heart of its reasoning is the “double negative” inference, based in the “probabilistic modus tollens.” The jargon name for this approach is “null hypothesis significance testing.” We will observe how and why it works, building up from some foundational concepts.
Reading Hacking, Chapter 17 “Normal Approximations” Hacking, Chapter 18 “Significance and Power” (note on type I/II error) Slides Introducing null-hypothesis testing Introduction to population sampling and correlation Learning questions How does the relative frequency interpretation of probability give rise to a way of justifying scientific knowledge?</description>
    </item>
    
    <item>
      <title>Topic 6: Causation</title>
      <link>http://chreliot.github.io/phi152/topics/causation/</link>
      <pubDate>Fri, 24 Apr 2020 11:09:33 -0400</pubDate>
      
      <guid>http://chreliot.github.io/phi152/topics/causation/</guid>
      <description>We&amp;rsquo;ve discussed what correlations are, and how they are related to sampling from a population via basic probability ideas. But we noted that correlation isn&amp;rsquo;t causation, and that researchers are quite often interested in causation. Here we take up how it might be possible to investigate causal relationships, and some of the challenges and limitations inherent to doing that.
Reading Kara Richardson. from “Avicenna’s Necessitation Thesis” (see Causation Readings) David Hume.</description>
    </item>
    
  </channel>
</rss>
