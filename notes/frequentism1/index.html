<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Frequentism1 | PHI 152</title>
    <link rel="stylesheet" href="/phi152/css/style.css" />
    <link rel="stylesheet" href="/phi152/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/phi152/">schedule</a></li>
      
      <li><a href="/phi152/topics">topics</a></li>
      
      <li><a href="/phi152/assignments">assignments</a></li>
      
      <li><a href="/phi152/tags/notes">notes</a></li>
      
      <li><a href="/phi152/resources">resources</a></li>
      
      <li><a href="/phi152/tests">tests</a></li>
      
      <li><a href="https://resources.us-east-1.linodeobjects.com/152-Syllabus-S22.pdf">syllabus</a></li>
      
      <li><a href="https://hofstra.blackboard.com">blackboard</a></li>
      
      <li><a href="/phi152/about">about</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Frequentism1</span></h1>

</div>

<main>
<h2 id="introducing-frequentist-scientific-reasoning">Introducing frequentist scientific reasoning</h2>
<h3 id="recall-bayesianisms--approach">Recall Bayesianism&rsquo;s  approach</h3>
<p>How does a Bayesian think we can reason from evidence to hypotheses?
How does evidence support hypotheses for Bayesians?</p>
<p>Your answers:</p>
<ul>
<li>Through probability and statistical analysis? Belief-type probability, esp. interpersonal
<ul>
<li>assigning a degree of belief to a hypothesis. Hypotheses have probabilities.</li>
</ul>
</li>
<li>evidence supports a hypothesis by making the hypothesis more probable than it was before.
<ul>
<li>In light of new evidence, we update the probability we assign to a hypothesis.</li>
</ul>
</li>
<li>Bayesianism suggests that evidence confirms a hypothesis if the probability of h|e is greater than the probability of just the hypothesis.</li>
</ul>
<p>What were some objections?</p>
<p>Your answers:</p>
<ul>
<li>P(H) is subjective not objective. This is the &ldquo;prior probability.&rdquo; If scientific reasoning means updating our subjective probabilities, it has an unscientific starting point.
<ul>
<li>Bayesian will reply that this doesn&rsquo;t matter in the long run, or we can sometimes ground P(H) in objective probabilities.</li>
</ul>
</li>
</ul>
<h3 id="high-res-audio-example">High res audio example</h3>
<p>Question: Can people tell the difference between hi-res (24 bit) and low-res (16 bit) samples of the same piece of music?</p>
<p>Test: Given recordings at high-res and low-res of the same piece, can you identify which one is which?</p>
<p>Data: % of people choosing sample 1 as high-res, % of people choosing sample 2 as high-res</p>
<p>If people cannot tell the difference: &ldquo;Their answers will vary&rdquo;; &ldquo;That the subjects should get 50% correct and 50% wrong&rdquo;</p>
<p>So we predict results that look like 50% of people choose sample 1, 50% choose sample 2. That&rsquo;s because the results would imitate randomness.</p>
<p>Results:</p>
<p>About half of the respondents to the survey correctly chose the right sample.</p>
<p>Reasoning:</p>
<p>If people can&rsquo;t tell the difference, we expected the results to be those we would expect to be produced by random guessing.</p>
<p>The results were similar to what we would expect by chance. 206 correct answers, 214 wrong answers. (49% correct)</p>
<p>So, there is no evidence supporting the hypothesis.</p>
<p>Discussion:</p>
<p>What if 52% of the respondents had guessed correctly (and 48% incorrectly)? What would you make of that result? Is there support for the hypothesis?</p>
<p>Did we expect <em>exactly</em> 50% would be able to tell the difference? No. We expected that a proportion <em>similar</em> to 50% would get it right.</p>
<p>If you were to flip a coin 420 times, how many heads would you expect?</p>
<ul>
<li>50% heads, 210 heads</li>
<li>But a result <em>other than</em> exactly 210 is far more likely than exactly 210 (209 or 208 or 207, etc. or 211 or 212 or 213 etc.)</li>
<li>So, more carefully: we should expect a result <em>near</em> 210.</li>
</ul>
<p>So, in the high-res audio case, if the results are <em>near</em> 50/50, we think there&rsquo;s no support, and if they&rsquo;re <em>far</em> from 50/50 we think there <em>is</em> support for the hypothesis that people can hear the difference.</p>
<p>Hypothesis: People can hear the difference between high/low-resolution audio samples.</p>
<p>(1) For frequentists, the question of degree of support for a hypothesis is how near or far from what we would expect on the basis of chance the results are.</p>
<p>(2) The results are meaningful if they are far from what we expect if the hypothesis is <em>false</em>. (The double negative inference.)</p>
<p>If H is false, we expect E results.
If actual results R are far from E, H is supported.
If actual results R are similar to E, H is not supported.</p>

</main>

  <footer>
  
  <hr/>
  ©2023 C. Eliot <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC</a> |  <a href="mailto:Christopher.H.Eliot@hofstra.edu">mail</a> | <a href="https://twitter.com/HofstraPhil">@HofstraPhil</a> | <a href="https://www.hofstra.edu/academics/colleges/hclas/phi/">HUφ</a> | <a href="https://chreliot.github.io/dasr">MDASR</a>
  
   | page updated: 2023-03-29 08:36 EDT 

  </footer>
  </body>
</html>

