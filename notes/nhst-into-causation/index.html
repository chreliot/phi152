<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NHST into Causation | PHI 152</title>
    <link rel="stylesheet" href="/phi152/css/style.css" />
    <link rel="stylesheet" href="/phi152/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/phi152/">schedule</a></li>
      
      <li><a href="/phi152/topics">topics</a></li>
      
      <li><a href="/phi152/assignments">assignments</a></li>
      
      <li><a href="/phi152/tags/notes">notes</a></li>
      
      <li><a href="/phi152/resources">resources</a></li>
      
      <li><a href="/phi152/tests">tests</a></li>
      
      <li><a href="https://resources.us-east-1.linodeobjects.com/152-Syllabus-S22.pdf">syllabus</a></li>
      
      <li><a href="https://hofstra.blackboard.com">blackboard</a></li>
      
      <li><a href="/phi152/about">about</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">NHST into Causation</span></h1>

</div>

<main>
<p><em>These were the on-screen notes based on the presentation and discussion during the remote session on Wed Apr 12.</em></p>
<h1 id="finishing-significance-testing-problems">Finishing significance testing problems</h1>
<ol start="5">
<li>P-hacking : Adjusting the way data is studied in order to achieve a &ldquo;significant&rdquo; p-value.</li>
</ol>
<p>A scientist claims that a particular political party being in power is good for the economy, that that is based on data, and that the claim is statistically significant (p &lt; 0.05). What question(s) should you ask?</p>
<p>ex: Democrats are good for the economy (p &lt;0.01).</p>
<ul>
<li>Could we ask what are the patterns to the suggested significant results?</li>
<li>Ask where the data came from and the validity of the source?</li>
<li>What are the parameters that a good economy is measured by?</li>
</ul>
<p>So, statistically significant support for the claimed association depends on how we define terms in terms of the available data.</p>
<ul>
<li>What does &ldquo;Democrat&rdquo; mean? Who&rsquo;s included in that?</li>
<li>What does &ldquo;good for the economy&rdquo; or &ldquo;economy&rdquo; mean? What&rsquo;s included in that?</li>
<li>Are there reasons that some data should be excluded?</li>
</ul>
<p>The problem is that we can give <em>reasons</em> for many different choices made above. So, different choices are not necessarily dishonest or bad practice. But it also seems like it leads to our being able to misrepresent the support or lack of support for a hypothesis.</p>
<p>So, the solution is not just asking researchers to be honest. What should researchers do or avoid doing if they want to be clear about how much support there is for hypotheses?</p>
<ul>
<li>Make sure that terms are well-defined. &ldquo;How are you measuring X?&rdquo;</li>
<li>Ask &ldquo;How would the result(s) <em>differ</em> if terms were defined differently?&rdquo;</li>
<li>Some researchers argue against &ldquo;HARKing&rdquo; (hypothesizing after the results are known). Make hypotheses and define terms <em>before</em> collecting data. Then collect data and assess degree of support, instead of rooting around in the data for significant associations.
BUT: This would exclude a lot of retrospective data-science.</li>
<li>At least for experimental studies, require &ldquo;pre-registration.&rdquo; Researchers declare in advance what hypotheses they intend to study and how they intend to study them (what data will be collected, and how they&rsquo;re defining terms).</li>
</ul>
<p>This plus &ldquo;The File Drawer Problem&rdquo; are significant problems that may be producing &ldquo;the replication crisis.&rdquo;</p>
<p>The File Drawer Problem is the problem that a particular lab will keep its studies that don&rsquo;t have statistically significant results in &ldquo;the file drawer&rdquo; (i.e., not published). Moreover, academic journals normally do not publish negative results. So, in combination with the recognition that we will fairly often (~5% of the time?) find statistically-significant results that do not reflect actual relationships in the world, this suggests that a significant portion of published papers may show support for claims that is not really there.</p>
<h1 id="causation">Causation</h1>
<blockquote>
<p>The magistrate, in consternation,
appealed to him: &ldquo;How can you be clear,&rdquo; [that you are not causing fits]
when your appearance is thus seen producing such
effects before our eyes? Then the children went
into fits all together,</p>
</blockquote>
<p>An apparent paradox:</p>
<ul>
<li>We cannot observe instances of causation.</li>
<li>Science culminates in identifying causal relationships.</li>
<li>Science should be entirely based on observation.</li>
</ul>
<p>These three claims can&rsquo;t all be true. Which one(s) is/are wrong?</p>

</main>

  <footer>
  
  <hr/>
  ©2023 C. Eliot <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC</a> |  <a href="mailto:Christopher.H.Eliot@hofstra.edu">mail</a> | <a href="https://twitter.com/HofstraPhil">@HofstraPhil</a> | <a href="https://www.hofstra.edu/academics/colleges/hclas/phi/">HUφ</a> | <a href="https://chreliot.github.io/dasr">MDASR</a>
  
   | page updated: 2023-04-12 13:31 EDT 

  </footer>
  </body>
</html>

